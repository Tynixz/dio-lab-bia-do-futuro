# o primeiro bloco de informa√ß√£o deve ser dos dados que ser√£o carregados. Para isso ele precisa de duas bibliotecas, do JSON e PANDAS
import json
import pandas as pd
import requests
import streamlit as st
import os 

#problema para encontrar o caminho de cada documento

BASE_DIR = os.path.dirname(os.path.abspath(__file__)) 
DATA_DIR = os.path.join(BASE_DIR, "..", "data")


#=============== CONFIGURA√á√ÉO =================
OLLAMA_URL = "http://localhost:11434/api/generate"
MODELO = "gpt-oss"

#================= CARREGAR DADOS ================
transacoes = pd.read_csv(os.path.join(DATA_DIR, "transacoes.csv"))
assinaturas = pd.read_csv(os.path.join(DATA_DIR, 'assinaturas.csv'), sep=",", encoding="utf-8")
dividas = pd.read_csv(os.path.join(DATA_DIR, 'dividas.csv'))
metas = pd.read_csv(os.path.join(DATA_DIR, 'metas.csv'))
                    
with open(os.path.join(DATA_DIR, "clientes.json"), encoding="utf-8") as f:
    clientes = json.load(f)

with open(os.path.join(DATA_DIR, "glossario_financeiro.json"), encoding="utf-8") as f:
    glossario = json.load(f)

with open(os.path.join(DATA_DIR, "produtos_financeiros.json"), encoding="utf-8") as f:
    produtos = json.load(f)

with open(os.path.join(DATA_DIR, "regras_orcamento.json"), encoding="utf-8") as f:
    regras_orcamento = json.load(f)


# como eu tenho uma lista com mais de 1 usu√°rio, preciso primeiro saber qual usu√°rio est√° utilizando o chat

#================= PEGAR NOME DO USU√ÅRIO =====================                 NO STREAMLIT
nome_digitado = st.text_input("Digite seu primeiro nome para acessar seus dados:").strip().lower()
if not nome_digitado:
    st.warning("Por favor, digite seu primeiro nome para continuar.")
    st.stop()

#================= BUSCAR CLIENTE =====================
cliente_encontrado = None

for c in clientes:
    primeiro_nome = c["nome_completo"].split()[0].lower() #lower para independer de como a pessoa escrever, conseguirmos encontrar no Sistema
    if primeiro_nome == nome_digitado:
        cliente_encontrado = c
        break #s√≥ isso que √© preciso fazer.

if cliente_encontrado is None: #se n√£o encontrar o nome do cliente, fecha o programa. ISSO USANDO NO STREAMLIT
    st.error("Cliente n√£o encontrado. Verifique o nome e tente novamente.")
    st.stop()



#=============== PEGAR ID DO CLIENTE ==================
id_cliente = cliente_encontrado["id_cliente"]


#Encontraando o ID do cliente, todos os dados das outras planilhas estar√£o vinculados por esse ID.

#================= FILTRAR DADOS =====================
transacoes_cliente = transacoes[transacoes["id_cliente"] == id_cliente] #primeiro pego a planilha "transacoes", depois procuro as transa√ß√µes do id do cliente. Usando novamente "transacoes" no c√≥digo ela vai pegas os valores das linhas "true", ou seja, as linhas que ouve transacao daquele id do usu√°rio. E o id precisa ser == aoa id_usuario que pegamos anteriormente com o primeiro nome da pessoa
assinaturas_cliente = assinaturas[assinaturas["id_cliente"] == id_cliente]
dividas_cliente = dividas[dividas["id_cliente"] == id_cliente]
metas_cliente = metas[metas["id_cliente"] == id_cliente]

#Como foi feita uma tabela apenas para as d√≠vidas de cada cliente, abaixo fa√ßo a conta para saber o total que falta para quitar a d√≠vida.
#No caso da meta, vai somar op valor total que j√° tem para as metas. O ".sum()" est√° ali para somar caso o cliente tenha mais de uma meta.

#================= C√ÅLCULOS =====================
total_divida_restante = (dividas_cliente["parcela_mensal"] * dividas_cliente["parcelas_restantes"]).sum()
reserva_atual = metas_cliente["valor_atual"].sum()


#Agora precisamos montar o nosso contexto. Primeiro carregar as info dos arquivos e carregar as info do cliente que estiver ali, como fiz acima 
# e abaixo eu darei um contexto a minha IA quando for usar.

#============== MONTAR CONTEXTO =================

contexto = f"""
CLIENTE: {cliente_encontrado['nome_completo']}, {cliente_encontrado['idade']} anos, perfil {cliente_encontrado['perfil_investidor']}
OBJETIVO: {cliente_encontrado['objetivo_principal']}
RENDA: R$ {cliente_encontrado['renda_mensal']} | RESERVA ATUAL: R${reserva_atual:.2f}

TRANSA√á√ïES RECENTES:
{transacoes_cliente.to_string(index=False)}

D√çVIDAS RESTANTES:
R$ {total_divida_restante:.2f}

PRODUTOS DISPON√çVEIS:
{json.dumps(produtos, indent=2, ensure_ascii=False)}
"""
# RESUMO: cliente_encontrado = serve para pegar dados do cliente e montar texto no contexto. Tr√°s a ficha completa do cliente.
#         id_cliente = serve para filtrar tabelas e puxar transa√ß√µes, d√≠vidas, metas, etc. Apenas para cruzar as tabelas.


# O escrito em docs/03-prompts

#============== SYSTEM PROMPT ===================

SYSTEM_PROMPT = """Voc√™ √© a V√™nus, uma assistente pessoal de finan√ßas especializada em Organiza√ß√£o Financeira B√°sica e Educa√ß√£o Financeira.

Seu objetivo √© direcionar o cliente a fazer escolhas melhores: onde gastar, onde n√£o gastar, como guardar dinheiro, onde, etc. Tudo como uma professora gente boa, falando de um jeito simples.
A V√™nus (seu nome como assistente pessoal de finan√ßas) analisa informa√ß√µes do cliente como renda, perfil de investidor, transa√ß√µes, assinaturas, d√≠vidas e metas financeiras, para sugerir:
- ajustes de or√ßamento por categoria (moradia, alimenta√ß√£o, lazer e transporte)
- identifica√ß√£o de gastos recorrentes desnecess√°rios
- estrat√©gias para quitar d√≠vidas com maior impacto de juros
- recomenda√ß√µes educativas de produtos financeiros compat√≠veis com o perfil do cliente
- explica√ß√µes simples de termos financeiros utilizando gloss√°rio interno

Exemplo de estilo:
Responda sempre de forma simples, com emojis e listas curtas quando necess√°rio.


REGRAS:
1. Sempre baseie suas respostas nos dados fornecidos
2. Nunca invente informa√ß√µes financeiras
3. Se n√£o souber algo, admita e ofere√ßa alternativas
4. Nunca forne√ßa dados de outro cliente
5. Nunca exibir CPF, n√∫mero de conta, cart√£o, endere√ßo, telefone ou dados banc√°rios.
6. Se o nome do cliente N√ÉO estiver dispon√≠vel no contexto, pe√ßa o nome antes de responder. 
7. Responda de forma sucinta e direta, com no m√°ximo 2 par√°grafos
8. Sempre responda de forma simples e interessante para ser lido (uso de emote e listas)
"""
#alterei a regra 6 para que o chat s√≥ pergunte novamente o nome (pois perguntar√° antes para saber o id) caso ele n√£o tenha id encontrado.


#Ollama √© o meu "chatGPT" de gra√ßa e de forma local.
#Essa √© a integra√ß√£o com o Ollama:

# =========== CHAMAR OLLAMA ================
def perguntar(msg):
    prompt = f"""
    {SYSTEM_PROMPT}

    CONTEXTO DO CLIENTE:
    {contexto}

    pergunta: {msg}"""
    
    r = requests.post(OLLAMA_URL, json={"model": MODELO, "prompt": prompt, "stream": False})
    return r.json()['response']

# Agora √© fazer isso tudo virar um chat. Os dados,etc. E agora, como etapa final vamos criar uma INTERFACE do STREAMLIT.
#Streamlit √© uma biblioteca em Python, OpenSource, onde vamos poder criar rapidamentes chatbots. Aplica√ß√µes voltadas para LLMs.
#Ele faz um FrontEnd atrav√©s de alguns facilitadores. Assim podemos fazer ele virar um chat bot.
#Usaremos essa ferramenta para acelerar esse desenvolvimento.


#========== INTERFACE ===============
st.title("Ol√°! Sou V√™nus, sua assistente pessoal de finan√ßas üíú")

if "mensagens" not in st.session_state: # Se ainda n√£o existe uma lista chamada mensagens, crie.
    st.session_state.mensagens = []  # o "st.session_state" √© uma caixinha de mem√≥ria do Streamlit, guarda os dados enquanto √© utilizado.
                                     #toda vez que voc√™ envia uma mensagem, o Streamlit reexecuta o c√≥digo inteiro do come√ßo.
                                     #Ent√£o se voc√™ n√£o guardar as mensagens no "session_state", o chat reinicia toda hora.

#Mostra hist√≥rico
for msg in st.session_state.mensagens:    #Para cada mensagem salva no hist√≥rico, mostre ela na tela. √â um loop, ele vai passando por cada item da lista.
    st.chat_message(msg["role"]).write(msg["content"]) #"st.chat_message(msg["role"])" Esse comando cria um bal√£o de chat.
                                                       #E o "msg["role"]" define quem est√° falando. "user" = bal√£o do usu√°rio   "assistant" = bal√£o da V√™nu
                                                       #  "msg["role"]" = quem falou     "msg["content"]" = o que foi dito

#input do usu√°rio
if pergunta := st.chat_input("Sua d√∫vida sobre finan√ßas..."): # :=  = walrus operator ("Pegue o que o usu√°rio digitou e j√° guarde na vari√°vel pergunta.")
    st.session_state.mensagens.append({"role":"user","content": pergunta})
    st.chat_message("user").write(pergunta) #Isso cria um bal√£o do usu√°rio e escreve o texto digitado. Exibindo na tela.

    with st.spinner("V√™nus est√° pensando..."): #st.spinner() Mostra um loading animado, tipo uma ampulheta do lado. O "with" √© para Enquanto eu estiver executando esse bloco, mostra o spinner.
        resposta = perguntar(pergunta)         # usu√°rio manda pergunta   Streamlit chama perguntar()     Ollama responde       salva na vari√°vel resposta


    st.session_state.mensagens.append({"role":"assistant", "content": resposta}) #salva a resposta da IA
    st.chat_message("assistant").write(resposta) #Cria o bal√£o da V√™nus e escreve a resposta.

#Ollama seria o c√©rebro enquando o Streamlit a tela onde o usu√°rio conversa
